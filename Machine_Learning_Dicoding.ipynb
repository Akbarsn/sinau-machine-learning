{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Dicoding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV_t4RrHtMyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Gdrive Folder\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI00wLS9r0qG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Membaca CSV menjadi dataframes panda\n",
        "import pandas as pd\n",
        "import os\n",
        "os.listdir('sample_data')\n",
        "df = pd.read_csv('sample_data/california_housing_train.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCFN4oFU5uzZ",
        "colab_type": "text"
      },
      "source": [
        "Source Code dibawah adalah untuk data preprocessing menggunakan MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65JqEJflr4lT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparasi Data menggunakan metode MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]\n",
        "scaler = MinMaxScaler().fit(data)\n",
        "print(scaler.transform(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5rBppOx55ur",
        "colab_type": "text"
      },
      "source": [
        "Source Code dibawah adalah untuk data preprocessing menggunakan StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMJ-W06wr4T7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparasi Data menggunakan metode Standarisasi\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "data = [[12000000, 33], [35000000, 45], [4000000, 23], [6500000, 26], [9000000, 29]]\n",
        "scaler = StandardScaler().fit(data)\n",
        "print(scaler.transform(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT0ahI4D6Ehn",
        "colab_type": "text"
      },
      "source": [
        "Source Code untuk pembagian dataset menjadi data train dan data test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3vc-Oicr4K1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pembagian Dataset menjadi test dan training\n",
        "# Data untuk test hanya sebesar 10% atau kurang\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "print(len(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOxVFkXC6LLY",
        "colab_type": "text"
      },
      "source": [
        "Evaluasi data menggunakan metode Cross Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vn7Vq6Br3_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "79491076-61d0-4476-ae7c-17865498b50f"
      },
      "source": [
        "# Data evaluation menggunakan metode Cross Validation Split\n",
        "# Mengecek akurasi tiap fold\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import tree\n",
        "iris = datasets.load_iris()\n",
        "x, y = iris.data, iris.target\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "scores = cross_val_score(clf, x, y, cv=5)\n",
        "print(scores)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.96666667 0.96666667 0.9        1.         1.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIGu583V6mSp",
        "colab_type": "text"
      },
      "source": [
        "Supervised Learning menggunakan decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kF2z_1nr9_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Supervised Learning\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "import os\n",
        "# os.listdir('Colab Notebooks')\n",
        "iris = pd.read_csv('/gdrive/My Drive/Colab Notebooks/Iris.csv')\n",
        "iris.drop('Id', axis=1, inplace=True)\n",
        "x = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "y = iris['Species']\n",
        "# Instansiasi Classifier Berbentuk Decision Tree\n",
        "tree_model = DecisionTreeClassifier()\n",
        "# Melakukan training model terhadap data\n",
        "tree_model.fit(x,y)\n",
        "# Memprediksi hasil dari suatu attribut\n",
        "tree_model.predict([[6.2, 3.4, 5.4, 2.3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XwdJvs8u_oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eksport hasil dari source kode diatas\n",
        "from sklearn.tree import export_graphviz\n",
        "export_graphviz(\n",
        "    tree_model,\n",
        "    out_file = \"iris_tree.dot\",\n",
        "    feature_names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'],\n",
        "    class_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica' ],\n",
        "    rounded= True,\n",
        "    filled =True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHBRt_Q_62SK",
        "colab_type": "text"
      },
      "source": [
        "Klasifikasi dengan menggunakan Linear Regresi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evRSLJskAWRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Klasifikasi Linear Regresi\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "bedrooms = np.array([1,1,2,2,3,4,4,5,5,5])\n",
        "house_price = np.array([15000, 18000, 27000, 34000, 50000, 68000, 65000, 81000,85000, 90000])\n",
        "# %matplotlib inline\n",
        "plt.scatter(bedrooms, house_price)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "bedrooms = bedrooms.reshape(-1,1)\n",
        "linreg = LinearRegression()\n",
        "linreg.fit(bedrooms, house_price)\n",
        "\n",
        "plt.scatter(bedrooms, house_price)\n",
        "plt.plot(bedrooms, linreg.predict(bedrooms))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUM2AF3d69b5",
        "colab_type": "text"
      },
      "source": [
        "Klasifikasi menggunakan Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItdNxvXGWroG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Logistic Regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/Social_Network_Ads.csv')\n",
        "# df.head()\n",
        "# df.info()\n",
        "data = df.drop(columns=['User ID'])\n",
        "data = pd.get_dummies(data)\n",
        "# data\n",
        "predictions = ['Age' , 'EstimatedSalary' , 'Gender_Female' , 'Gender_Male']\n",
        "x = data[predictions]\n",
        "y = data['Purchased']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
        "\n",
        "from sklearn import linear_model\n",
        "model = linear_model.LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "model.score(x_test, y_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEMdx3bn7NLq",
        "colab_type": "text"
      },
      "source": [
        "Clustering dengan menggunakan metode KNN (K Nearest Neighbour) dan menggunakan metode elbow untuk mendapatkan nilai K terbaik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpC1yXz-ptuv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# Membaca dataset dari csv\n",
        "df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/Mall_Customers.csv')\n",
        "df = df.rename(columns={'Gender':'gender' , 'Age':'age' , \n",
        "                        'Annual Income (k$)': 'annual_income',\n",
        "                        'Spending Score (1-100)': 'spending_score'})\n",
        "# Mengubah value kolom gender menjadi 0 untuk wanita dan 1 untuk pria\n",
        "df['gender'].replace(['Female', 'Male'], [0,1], inplace=True)\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUl825DB7yy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "X = df.drop(['CustomerID', 'gender'], axis=1)\n",
        "# Cari inertia\n",
        "clusters = []\n",
        "for i in range(1,11):\n",
        "  km = KMeans(n_clusters=i).fit(X)\n",
        "  clusters.append(km.inertia_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR97KyCL72IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Buat graph untuk menentukan K\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "sns.lineplot(x=list(range(1, 11)), y=clusters, ax=ax)\n",
        "ax.set_title('Cari Elbow')\n",
        "ax.set_xlabel('Clusters')\n",
        "ax.set_ylabel('Inertia')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyzAD87x76QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instansiasi KMeans dengan 5 cluster\n",
        "km5 = KMeans(n_clusters=5).fit(X)\n",
        "X['Labels'] = km5.labels_\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.scatterplot(X['annual_income'], X['spending_score'], hue=X['Labels'],\n",
        "                palette=sns.color_palette('hls', 5))\n",
        "plt.title('KMeans dengan 5 Cluster')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbNAq6EJ7zBK",
        "colab_type": "text"
      },
      "source": [
        "Penggunaan PCA (Principal Component Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fFVMcZ0sSVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "\n",
        "# Menggunakan dataset iris\n",
        "iris = datasets.load_iris()\n",
        "# Membagi dataset menjadi attribut dan label\n",
        "attribut = iris.data\n",
        "label = iris.target\n",
        "# Membagi dataset untuk train dan test\n",
        "x_train, x_test, y_train, y_test = train_test_split(attribut, label, \n",
        "                                                    test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyOeflYc7_xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Menggunakan model tree biasa sebagai pembanding\n",
        "from sklearn import tree\n",
        "decision_tree = tree.DecisionTreeClassifier()\n",
        "model_pertama = decision_tree.fit(x_train, y_train)\n",
        "model_pertama.score(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kYwaZM18APx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pencarian Principal Component\n",
        "pca = PCA(n_components=4)\n",
        "pca_attributes = pca.fit_transform(x_train)\n",
        "pca.explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEW8gL548fu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merubah dataset menggunakan 2 principal component saja\n",
        "pca = PCA(n_components=2)\n",
        "x_train_pca = pca.fit_transform(x_train)\n",
        "x_test_pca = pca.fit_transform(x_test)\n",
        "\n",
        "model_kedua = decision_tree.fit(x_train_pca, y_train)\n",
        "model_kedua.score(x_test_pca, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwaRb-Yf8A5L",
        "colab_type": "text"
      },
      "source": [
        "Penggunaan SVC (Support Vector Classification)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZvlE3qj-Wb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/gdrive/My Drive/Colab Notebooks/diabetes.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS_7asfw-spk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Menunjukkan info dari dataset\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIGpj3qY-unR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Memisahkan antara attribut dan label\n",
        "x = df[df.columns[:8]] # attribut\n",
        "y = df['Outcome'] # label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RuN7T3A-uj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessing data dengan men-standarisasi nilai di dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "x = scaler.transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Rj1JpJ_PMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Membagi data menjadi data train dan data test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIUr_2Ud_ohQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Support Vector Classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(x_train, y_train)\n",
        "clf.score(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfRcRO288LcC",
        "colab_type": "text"
      },
      "source": [
        "Penggunaan SVR (Support Vector Regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J5-5Cc-HpvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = pd.read_csv('/gdrive/My Drive/Colab Notebooks/Salary_Data.csv')\n",
        "data.info()\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqkb9-9oL6cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = data['YearsExperience']\n",
        "y = data['Salary']\n",
        "x = x[:,np.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuS3uA6HMEDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "model = SVR(C=1000, gamma=0.05, kernel='rbf')\n",
        "model.fit(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L834RBB2MRok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, model.predict(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8es0gtI8T_8",
        "colab_type": "text"
      },
      "source": [
        "Penggunaan metode Grid Search untuk mencari nilai parameter terbaik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAqtcq1cRWmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mencari parameter terbaik menggunakan metode Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "model = SVR()\n",
        "parameters = {\n",
        "    'kernel': ['rbf'],\n",
        "    'C':     [1000, 10000, 100000],\n",
        "    'gamma': [0.5, 0.05,0.005]\n",
        "}\n",
        "grid_search = GridSearchCV(model, parameters)\n",
        "grid_search.fit(x,y)\n",
        "print(grid_search.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50l_jx0URd6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Membuat model baru\n",
        "model_baru = SVR(kernel='rbf', C=100000, gamma=0.005)\n",
        "model_baru.fit(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qomp5volRuvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Menampilkan hasil\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, model_baru.predict(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nerqdvIU8blM",
        "colab_type": "text"
      },
      "source": [
        "Penggunaan CNN (Convolution Neural Network) dengan tensorflow untuk klasifikasi gambar kamar kotor dan kamar rapi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPlU50iJSBLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3wy-wHvgG9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pemula_academy/messy-vs-clean-room.zip \\\n",
        "  -O /tmp/messy_vs_clean_room.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xWSAhr0gN2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile,os\n",
        "local_zip = '/tmp/messy_vs_clean_room.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        " \n",
        "base_dir = '/tmp/images'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNWSPQZ5gRd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('/tmp/images/train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2QH1piugTjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('/tmp/images/val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPOq_MewgXiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_clean_dir = os.path.join(train_dir, 'clean')\n",
        "\n",
        "train_messy_dir = os.path.join(train_dir, 'messy')\n",
        "\n",
        "validation_clean_dir = os.path.join(validation_dir, 'clean')\n",
        "\n",
        "validation_messy_dir = os.path.join(validation_dir, 'messy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CRAG4MDg-RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        " \n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTaJgk_rhAqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # direktori data latih\n",
        "        target_size=(150, 150),  # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
        "        batch_size=4,\n",
        "        # karena kita merupakan masalah klasifikasi 2 kelas maka menggunakan class_mode = 'binary'\n",
        "        class_mode='binary')\n",
        " \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir, # direktori data validasi\n",
        "        target_size=(150, 150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
        "        batch_size=4, # karena kita merupakan masalah klasifikasi 2 kelas maka menggunakan class_mode = 'binary'\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4pxoOJphMsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator, # menampilkan akurasi pengujian data validasi\n",
        "      validation_steps=5,  # berapa batch yang akan dieksekusi pada setiap epoch\n",
        "      verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdW27OFGhWDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        " \n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  \n",
        "  print(fn)\n",
        "  if classes==0:\n",
        "    print('clean')\n",
        "  else:\n",
        "    print('messy')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}